[33mcommit 834f90f2f866cdd3a9b7f084c14fa8961f025502[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmain[m[33m, [m[1;31morigin/master[m[33m, [m[1;32mmaster[m[33m)[m
Author: Raul Osorio <raul.153@hotmail.com>
Date:   Tue Apr 16 23:36:14 2024 -0300

    Project Conclusion

[1mdiff --git a/requirements.txt b/requirements.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..7b19ef5[m
[1m--- /dev/null[m
[1m+++ b/requirements.txt[m
[36m@@ -0,0 +1,2 @@[m
[32m+[m[32mbeautifulsoup4==4.9.1[m
[32m+[m[32mrequests==2.23.0[m
[1mdiff --git "a/scraped_articles/How_One_Developer_Accidentally_Stopped_the_World\342\200\231s_Most_Dangerous_Hack.txt" "b/scraped_articles/How_One_Developer_Accidentally_Stopped_the_World\342\200\231s_Most_Dangerous_Hack.txt"[m
[1mnew file mode 100644[m
[1mindex 0000000..e540633[m
[1m--- /dev/null[m
[1m+++ "b/scraped_articles/How_One_Developer_Accidentally_Stopped_the_World\342\200\231s_Most_Dangerous_Hack.txt"[m
[36m@@ -0,0 +1,19 @@[m
[32m+[m[32mURL: https://medium.com/gitconnected/how-one-developer-prevented-millions-of-machines-from-getting-compromised-by-accident-72da8af2d76e[m
[32m+[m
[32m+[m[32mTitle: HOW ONE DEVELOPER ACCIDENTALLY STOPPED THE WORLD‚ÄôS MOST DANGEROUS HACK[m
[32m+[m
[32m+[m[32mMember-only story[m
[32m+[m
[32m+[m[32mEVERYTHING YOU NEED TO KNOW ABOUT THE MOST DANGEROUS HACK THAT WAS ABOUT TO HAPPEN, BUT LUCKILY GOT DISCOVERED.[m
[32m+[m
[32m+[m[32mVivek Naskar[m
[32m+[m[32mFollow[m
[32m+[m[32mLevel Up Coding[m
[32m+[m[32m--[m
[32m+[m[32m11[m
[32m+[m[32mShare[m
[32m+[m[32mIn 2021, the vulnerability in the Java logging library Apache Log4j 2 called ‚ÄúLog4Shell‚Äù was touted as the most critical vulnerability of the last decade. It made developers all around the world work on millions of apps to fix that critical vulnerability with a non-vulnerable version.[m
[32m+[m[32mImagine there‚Äôs a vulnerability of that scale, but it‚Äôs 1000x that would affect almost all the systems around the world. Yes, you heard that right.[m
[32m+[m[32mThe bad actor or actors (not sure if it‚Äôs one person but a full-fledged team) inserted ‚Äúmalicious code‚Äù in the open-source library called XZ Utils, which is a command-line tool for data compression that is widely used in major Linux distributions.[m
[32m+[m[32mWell, this malicious code is actually a backdoor for remote code execution. This would have enabled hackers to take over all Linux systems around the world![m
[32m+[m[32mThis compromise was found out by Microsoft engineer and PostgreSQL developer, Andres Freund, on March 29, 2024, and he found out‚Ä¶[m
\ No newline at end of file[m
[1mdiff --git a/scraped_articles/You_can_learn_anything_in_IT_for_FREE!.txt b/scraped_articles/You_can_learn_anything_in_IT_for_FREE!.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..7b75bb9[m
[1m--- /dev/null[m
[1m+++ b/scraped_articles/You_can_learn_anything_in_IT_for_FREE!.txt[m
[36m@@ -0,0 +1,72 @@[m
[32m+[m[32mURL: https://medium.com/@sam5epi0l/you-can-learn-anything-in-it-for-free-e54120458d95[m
[32m+[m
[32m+[m[32mTitle: YOU CAN LEARN ANYTHING IN IT FOR FREE![m
[32m+[m
[32m+[m[32mPradeep J.[m
[32m+[m[32mFollow[m
[32m+[m[32m--[m
[32m+[m[32mListen[m
[32m+[m[32mShare[m
[32m+[m[32mThis article has everything you need to master any Technical and IT skills and it also contains an uncomplicated roadmap which will push you from zero to hero in IT.[m
[32m+[m[32mIt took a long time to write this article as I wanted to gather all things which are helpful. This article is written over my experience, but not limited to, on how I went from having zero knowledge of IT and other skills to successfully working as a Content creator, Programmer, DevOps, Sysadmin, Architect, and of course, as a Security Engineer without any degree, cert, or training.[m
[32m+[m
[32m+[m[32mSO, HERE THE QUESTION ARISES. WHY DO YOU NEED TO LEARN BY YOUR OWN?[m
[32m+[m
[32m+[m[32mBinging and being overindulge in courses is like fish in a bowl. Most of the courses and degrees are designed in such a way that their content will make you feel as enough and you have mastered all skills but the bitter truth is that it is not as sufficient and also limits the creativity of your own mind.[m
[32m+[m[32mPro of this methodology (learning by your self) is that You‚Äôre free to wander and think out of the box which will make you figure out and provides you expertise related to IT.[m
[32m+[m
[32m+[m[32mOBVIOUS PREREQUISITES:[m
[32m+[m
[32m+[m[32m - First, the PC, make your Desktop screen Flawless and remove all distractions.[m
[32m+[m[32m - Internet. (2 GB per day mostly)[m
[32m+[m[32m - Hunger / Curiosity to learn.[m
[32m+[m[32m - Discipline to practice.[m
[32m+[m[32m - Self driven mindset.[m
[32m+[m[32m - Computer Fundamentals.[m
[32m+[m
[32m+[m[32mWHAT CONTENT TO CHOOSE? üçä[m
[32m+[m
[32m+[m[32mIn beginning, Always prefer more valuable community (Language: English, Mandarin, French) Twitter, Reddit, GitHub, Medium, dev.to, etc.[m
[32m+[m[32mAgain, remove the distractions. Hack the algorithm of platform. Make it hard to sneak into distractions, so you stay focused on the goal.[m
[32m+[m[32mChoose content which makes you stop studying and makes practice more.[m
[32m+[m[32mHere is the straightforward roadmap to follow:[m
[32m+[m[32mThese are not in any specific order but use all of them as required¬†as¬†stated.[m
[32m+[m[32m - Find curated roadmap specific to the skill/technology at[m[41m [m
[32m+[m[32m - Setup Home Lab or Cloud lab (DigitalOcean referral link) which makes your productive on the actual task not the setup process by removing the breakpoints.[m
[32m+[m[32m - Get used to (Linux and optionally windows) command line. It won‚Äôt harm. Learn shell programming to automate tasks.[m
[32m+[m[32m - Master one language (Python or Go) and make something with it then learn multiple languages as you go. Focus on the core concept of the language.[m
[32m+[m[32m - Google every issue. Read complete (Stack Overflow) threads to understand and debug the problem.[m
[32m+[m[32m - Create GitHub+GitLab account. Search projects. See how people contribute. Support open source because it gives you freedom.[m
[32m+[m[32m - Make use of GitHub ‚Äú[m
[32m+[m[32m - Setup YouTube account to learn effectively:[m
[32m+[m[32m - Find more resources and specifically skill to learn on Subreddit(s) related to your niche. You may also get your queries already answered and cross-verified by community.[m
[32m+[m[32m - Watch talks, conferences, practical podcasts and keep up with the community using Mastodon and Twitter (X).[m
[32m+[m[32m - Make content. Publish to more reputed websites and for targeted audience. Example ‚Äî YouTube,[m[41m [m
[32m+[m[32m - Participate in live competitions, tournaments, or hackathons.[m
[32m+[m[32m - Contribute to Open source and not-profit organization.[m
[32m+[m[32m - Freelance (Upwork, Fiver). Learn to deal professionally.[m
[32m+[m[32m - If your brain pops with a decent project idea work on it.[m
[32m+[m[32m - Try to engage in communities such as discord and other forums.[m
[32m+[m[32mEveryone, at some point of time and effort gets burnout.[m
[32m+[m[32m - Take a break. If your life was already at a high speed take some time off before you start something new or something big. Then start with a fresh mind.[m
[32m+[m[32m - Start your day with full speed. Do one or more straightforward things from or outside the roadmap which sets you in the mood.[m
[32m+[m[32m - Avoid taking phone breaks. It ruins your attention span. Keep it away as much as you can.[m
[32m+[m[32m - Eat healthy. Exercise every day (but don‚Äôt do that much, that you feel low energy for whole day) Do 2‚Äì3 reps of push-ups at least every time you got stuck for a while.[m
[32m+[m[32m - Go out. Learn about people‚Äôs pain. That will make you remember that you are not living the hardest life, not even close.[m
[32m+[m[32m - Don‚Äôt get into money making too early, it's really a boring process. Nothing wrong with exploring though.[m
[32m+[m[32m - Get a balance in life. If you learn for 20 hours a week then it‚Äôs alright. But any more than that will require opposite activity to neutralize the effect and will keep mental health good.[m
[32m+[m[32m - Avoid thinking about AI. Except creating a project around it.[m
[32m+[m[32m - If you‚Äôre already weak mentally and have no one to support you. I recommend you to take a break from everything and just enjoy all day every day.[m
[32m+[m
[32m+[m[32mSPIRITUAL PHILOSOPHY üßò[m
[32m+[m
[32m+[m[32m - Pray throughout the day, every day for the good![m
[32m+[m[32m - One push-up (at least) on every distraction made. (no excuses)[m
[32m+[m[32m - Think about the life you are living. Know your responsibilities. Get angry and use your anger as weapon to work towards betterment![m
[32m+[m[32m - Lastly take this journey as a marathon. Consistently learn for decent time every week. It is the key.[m
[32m+[m[32mDoing things manually instead of getting into automation too early. And just learn how things actually work, will make this more fun.[m
[32m+[m[32mA great thanks to Sahils for collaborating and improving this article.[m
[32m+[m[32m - Follow me[m[41m [m
[32m+[m[32m - Clap to this article up to 50 times.[m
[32m+[m[32m - Leave feedback/tips/opinion in comments.[m
[32m+[m[32m - Say[m[41m [m
\ No newline at end of file[m
[1mdiff --git a/scraping_medium.py b/scraping_medium.py[m
[1mnew file mode 100644[m
[1mindex 0000000..063ea2e[m
[1m--- /dev/null[m
[1m+++ b/scraping_medium.py[m
[36m@@ -0,0 +1,71 @@[m
[32m+[m[32mimport os[m
[32m+[m[32mimport sys[m
[32m+[m[32mimport requests[m
[32m+[m[32mimport re[m
[32m+[m[32mfrom bs4 import BeautifulSoup[m
[32m+[m
[32m+[m[32mos.chdir(os.path.dirname(os.path.abspath(__file__)))[m
[32m+[m
[32m+[m[32m# Function to get the html of the page;[m
[32m+[m[32mdef get_page():[m
[32m+[m[32m    url = input('Enter URL of a medium article: ')[m
[32m+[m[32m    # handling possible error[m
[32m+[m[32m    if not re.match(r'https?://medium.com', url):[m
[32m+[m[32m        print('Please enter a valid website, or make sure it is a medium article')[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m[32m    headers = {[m
[32m+[m[32m        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'[m
[32m+[m[32m    }[m
[32m+[m[32m    res = requests.get(url, headers=headers)[m
[32m+[m[32m    res.raise_for_status()[m
[32m+[m[32m    soup = BeautifulSoup(res.text, 'html.parser')[m
[32m+[m[32m    return soup, url[m
[32m+[m
[32m+[m[32m# function to compile all of the scraped text in one string[m
[32m+[m[32mdef collect_text(soup, url):[m
[32m+[m[32m    fin = f'URL: {url}\n\n'[m
[32m+[m[32m    try:[m
[32m+[m[32m        title = soup.find('h1').text.strip()[m
[32m+[m[32m        fin += f'Title: {title.upper()}\n'[m
[32m+[m[32m    except AttributeError:[m
[32m+[m[32m        title = "No Title Found"[m
[32m+[m[32m        fin += "Title: No Title Found\n"[m
[32m+[m
[32m+[m[32m    article_body = soup.find('article')[m
[32m+[m[32m    if not article_body:[m
[32m+[m[32m        article_body = soup[m
[32m+[m
[32m+[m[32m    for element in article_body.find_all(['p', 'h2', 'h3', 'ul', 'ol']):[m
[32m+[m[32m        if element.name in ['h2', 'h3']:[m
[32m+[m[32m            fin += f'\n\n{element.text.upper()}\n'[m
[32m+[m[32m        elif element.name in ['ul', 'ol']:[m
[32m+[m[32m            for item in element.find_all('li'):[m
[32m+[m[32m                fin += f'\n - {purify(item.next)}'[m
[32m+[m[32m        else:[m
[32m+[m[32m            fin += f'\n{purify(element.text)}'[m
[32m+[m
[32m+[m[32m    return fin, title[m
[32m+[m
[32m+[m[32m# Function to remove all the html tags and replace some with specific strings[m
[32m+[m[32mdef purify(text):[m
[32m+[m[32m    rep = {"<br>": "\n", "<br/>": "\n", "<li>": "\n"}[m
[32m+[m[32m    rep = dict((re.escape(k), v) for k, v in rep.items())[m
[32m+[m[32m    pattern = re.compile("|".join(rep.keys()))[m
[32m+[m[32m    text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)[m
[32m+[m[32m    text = re.sub(r'\<(.*?)\>', '', text)[m
[32m+[m[32m    return text[m
[32m+[m
[32m+[m[32mdef save_file(fin, title):[m
[32m+[m[32m    dir_path = './scraped_articles'[m
[32m+[m[32m    if not os.path.exists(dir_path):[m
[32m+[m[32m        os.mkdir(dir_path)[m
[32m+[m[32m    file_name = '_'.join(title.split()) + '.txt'[m
[32m+[m[32m    file_path = os.path.join(dir_path, file_name)[m
[32m+[m[32m    with open(file_path, 'w', encoding='utf8') as file:[m
[32m+[m[32m        file.write(fin)[m
[32m+[m[32m    print('File Saved in directory {}'.format(file_path))[m
[32m+[m
[32m+[m[32mif __name__ == '__main__':[m
[32m+[m[32m    soup, url = get_page()[m
[32m+[m[32m    fin, title = collect_text(soup, url)[m
[32m+[m[32m    save_file(fin, title)[m
